{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json         # ms marco dataset in json format\n",
    "import itertools    # for dictionary slicing\n",
    "import re           # regular expression\n",
    "import os           # for file reading and writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Data with size of 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$./Data/dev\\_v2.1.json$ file is the original development data set from ms marco website.\n",
    "However, it is too huge for development with cpu. For faster computation, use following scripts to get the smaller dev dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 5000     # set the data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/original_dataset/dev_v2.1.json', 'r') as f:\n",
    "    data = json.load(f)    # load json file and save in variable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_id\n",
    "query_id = dict(itertools.islice(data[\"query_id\"].items(), data_size))\n",
    "\n",
    "# query (questions)\n",
    "query = dict(itertools.islice(data[\"query\"].items(), data_size))\n",
    "\n",
    "# query_type (e.g. numeric, description)\n",
    "query_type = dict(itertools.islice(data[\"query_type\"].items(), data_size))\n",
    "\n",
    "# passages -- 10 for each query\n",
    "passages = dict(itertools.islice(data[\"passages\"].items(), data_size))\n",
    "\n",
    "# answers\n",
    "answers = dict(itertools.islice(data[\"answers\"].items(), data_size))\n",
    "\n",
    "# wellFormedAnswers for intermediate tasks\n",
    "wellFormedAnswers = dict(itertools.islice(data[\"wellFormedAnswers\"].items(), data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the data\n",
    "json_data = {\"query_id\": query_id,\n",
    "             \"query\": query,\n",
    "             \"query_type\": query_type,\n",
    "             \"passages\": passages,\n",
    "             \"answers\": answers,\n",
    "             \"wellFormedAnswers\": wellFormedAnswers} # wellFormedAnswers are for intermediate tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data into separate file\n",
    "with open('./Data/devData_' + str(data_size) + '.json', 'w') as out_f:\n",
    "    json.dump(json_data, out_f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Data without \"No Answer Present.\"\n",
    "which means, answerable Data from the original development dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers with ANSWER not [\"No Answer Present.\"]\n",
    "have_answers = {k: v for (k, v) in data[\"answers\"].items() if v != [\"No Answer Present.\"]}\n",
    "\n",
    "# take query_id, query, query_type, passages of data with answers\n",
    "have_query_id = {k: v for (k, v) in data[\"query_id\"].items() if k in have_answers.keys()}\n",
    "have_query = {k: v for (k, v) in data[\"query\"].items() if k in have_answers.keys()}\n",
    "have_query_type = {k: v for (k, v) in data[\"query_type\"].items() if k in have_answers.keys()}\n",
    "have_passages = {k: v for (k, v) in data[\"passages\"].items() if k in have_answers.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the data\n",
    "have_answers_data = {\"query_id\": have_query_id,\n",
    "                     \"query\": have_query,\n",
    "                     \"query_type\": have_query_type,\n",
    "                     \"passages\": have_passages,\n",
    "                     \"answers\": have_answers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data into './Data/devData_answerable.json' file\n",
    "with open('./Data/devData_answerable.json', 'w') as out_f:\n",
    "    json.dump(have_answers_data, out_f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction data\n",
    "following cells should be run after the prediction mentioned in the $README.ipython$. Check the presence of prediction.json in $./MS\\_marco/$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### '$./prediction.json$' file structure"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "e.g. '10190' 'The average cost of a set of brake pads is $ 25â€“75 .' 0 50"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'<query_id>' '<predicted answer>' <start position of answer snippet> <end position of answer snippet>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from './prediction.json' file, extract query_ids and answers \n",
    "with open('./prediction.json', 'r') as pred_f:\n",
    "    ids = []\n",
    "    answer = []\n",
    "    for line in pred_f:\n",
    "        # split the line to read query_id and answer\n",
    "        component = re.findall(r\"'(?:[^'\\\\]|\\\\.)*'\", line)\n",
    "        qid = component[0]\n",
    "        if len(component) > 1:\n",
    "            sent = component[1]\n",
    "        else:\n",
    "            remain = line[line.find(' '):]\n",
    "            sent = re.findall(r'\\\"(.+?)\\\"', remain)[0]\n",
    "\n",
    "        qid = qid[1:-1]\n",
    "        # reformat the answer with double quotes single quote will cause an error during parsing\n",
    "        sent = '\"' + sent[1:-1] + '\"'\n",
    "        ids.append(qid)\n",
    "        answer.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./Data/devData_' + str(data_size) + '.json', 'r') as f:\n",
    "    ref = json.load(f)\n",
    "    ref_id = ref[\"answers\"].keys()\n",
    "    ref_ans = ref[\"answers\"].values()\n",
    "\n",
    "# only take the reference answer from the query that acutally have been predicted\n",
    "rid = []\n",
    "ranswers = []\n",
    "for id in ids:\n",
    "    rid.append(id)\n",
    "    ranswers.append(ref[\"answers\"][str(id)])\n",
    "\n",
    "temp = []\n",
    "for x, y in zip(rid, ranswers):\n",
    "    y = '[\"' + str(y[0]) + '\"]'\n",
    "    temp.append('{\"query_id\": %d, \"answers\": %s}' % (int(x), y))\n",
    "\n",
    "# write the reference file\n",
    "#############\n",
    "# BEFORE RUNNING THIS CELL DELETE THE './Data/reference.json'\n",
    "# It is because this script will append the data into the existing file\n",
    "#############\n",
    "with open('./Data/reference.json', 'a') as the_file:\n",
    "    for i in range(len(temp)):\n",
    "        the_file.write(temp[i])\n",
    "        the_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x, y in zip(ids, answer):\n",
    "    y = '[' + y + ']'\n",
    "    temp.append('{\"query_id\": %d, \"answers\": %s}' % (int(x), y))\n",
    "\n",
    "# write the candidate file\n",
    "#############\n",
    "# BEFORE RUNNING THIS CELL DELETE THE './Data/candidate.json'\n",
    "# It is because this script will append the data into the existing file\n",
    "#############\n",
    "with open('./Data/candidate.json', 'a') as the_file:\n",
    "    for i in range(len(temp)):\n",
    "        the_file.write(temp[i])\n",
    "        the_file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
